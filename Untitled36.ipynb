{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrj7kFsEvu63ChOqQetSA+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SahelKherad/3-story-benchmark-transformer/blob/main/Untitled36.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jESaGaJ8Y4fL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import scipy.io\n",
        "from scipy.io.matlab._mio5_params import mat_struct\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VnHyYOfY6Ts",
        "outputId": "45794844-cd39-4069-9b40-ad1b4eb904fe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/ASCE\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yoanGUbZwdT",
        "outputId": "c2d4f8c9-5dee-43ea-c05a-e636cb994526"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shm01a.mat  shm03a.mat\tshm05a.mat  shm07a.mat\tshm09a.mat\n",
            "shm02a.mat  shm04a.mat\tshm06a.mat  shm08a.mat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/ASCE/shm01a.mat'  # adjust if your filename differs\n",
        "data = scipy.io.loadmat(folder_path)\n",
        "\n",
        "print(data.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_7LbE3r6hHv",
        "outputId": "66f28761-b440-417d-dcd3-20ab7badfb40"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['__header__', '__version__', '__globals__', 'dasy', 'dasy_dscr', 'filedescription', 'fsdasy'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_mat(path):\n",
        "    # 1) load and squeeze singletons\n",
        "    mat = scipy.io.loadmat(path, squeeze_me=True, struct_as_record=False)\n",
        "    raw = mat.get('dasy')\n",
        "    if raw is None:\n",
        "        raise KeyError(f\"'dasy' not found in {path}; keys: {list(mat.keys())}\")\n",
        "\n",
        "    # 2) if it came in as a 0-d object array, unpack it\n",
        "    if isinstance(raw, np.ndarray) and raw.shape == () and isinstance(raw.item(), mat_struct):\n",
        "        raw = raw.item()\n",
        "\n",
        "    # 3) if it’s a mat_struct, each field is one channel’s data\n",
        "    if isinstance(raw, mat_struct):\n",
        "        fields = raw._fieldnames  # e.g. ['ch1', 'ch2', …]\n",
        "        channels = []\n",
        "        for f in fields:\n",
        "            arr = getattr(raw, f)\n",
        "            # arr may be shape (n,1) or (n,), so flatten\n",
        "            channels.append(np.asarray(arr).reshape(-1))\n",
        "        data = np.stack(channels, axis=1)  # → (n_samples, n_channels)\n",
        "\n",
        "    # 4) otherwise if it’s already an ndarray, use it\n",
        "    elif isinstance(raw, np.ndarray):\n",
        "        data = raw\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Cannot interpret dasy of type {type(raw)}\")\n",
        "\n",
        "    # 5) final sanity check\n",
        "    if not (isinstance(data, np.ndarray) and data.ndim == 2):\n",
        "        raise ValueError(f\"After unwrapping, expected 2‐D array but got shape {getattr(data,'shape',None)}\")\n",
        "\n",
        "    return data, mat\n",
        "\n",
        "\n",
        "# Now try your loading loop again:\n",
        "base_dir = '/content/drive/MyDrive/ASCE/'\n",
        "state_files = {\n",
        "    1: 'shm01a.mat',   # state 1 → label 0\n",
        "    2: 'shm02a.mat',   # state 3 → label 1\n",
        "    3: 'shm03a.mat',   # state 3 → label 2\n",
        "    4: 'shm04a.mat',   # state 3 → label 1\n",
        "    5: 'shm05a.mat',   # state 3 → label 1\n",
        "    6: 'shm06a.mat',   # state 3 → label 1\n",
        "    7: 'shm07a.mat',   # state 3 → label 1\n",
        "    8: 'shm08a.mat',   # state 3 → label 1\n",
        "    9: 'shm09a.mat',   # state 3 → label 1\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "-lNjv__AwP8T"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data, all_labels = [], []\n",
        "for label, fname in state_files.items():\n",
        "    path = os.path.join(base_dir, fname)\n",
        "    dasy, mat = load_mat(path)\n",
        "    print(f\"{fname}: data shape = {dasy.shape}\")\n",
        "    all_data.append(dasy)\n",
        "    all_labels.append(np.full(dasy.shape[0], label, dtype=np.int64))\n",
        "all_labels2 = np.concatenate(all_labels)\n",
        "print(all_labels2.shape)\n",
        "print(all_labels[5].shape)\n",
        "# print(all_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kt-q273eZ4vG",
        "outputId": "d6fd47bd-7b6a-4745-8228-775546c460c7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shm01a.mat: data shape = (60000, 16)\n",
            "shm02a.mat: data shape = (60000, 16)\n",
            "shm03a.mat: data shape = (60000, 16)\n",
            "shm04a.mat: data shape = (60000, 16)\n",
            "shm05a.mat: data shape = (60000, 16)\n",
            "shm06a.mat: data shape = (45568, 16)\n",
            "shm07a.mat: data shape = (180000, 16)\n",
            "shm08a.mat: data shape = (180000, 16)\n",
            "shm09a.mat: data shape = (180000, 16)\n",
            "(885568,)\n",
            "(45568,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_state1 = all_data[0]\n",
        "data_state2 = all_data[1]\n",
        "data_state3 = all_data[2]\n",
        "data_state4 = all_data[3]\n",
        "data_state5 = all_data[4]\n",
        "data_state6 = all_data[5]\n",
        "data_state7 = all_data[6]\n",
        "data_state8 = all_data[7]\n",
        "data_state9 = all_data[8]\n",
        "# print(data_state1.dtype)\n",
        "print(data_state1.shape)\n",
        "print(data_state6.shape)\n",
        "print(data_state8.shape)\n",
        "# print(data_state2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VVni1oHWagP",
        "outputId": "9791f138-c034-48a2-814c-74178afa6545"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 16)\n",
            "(45568, 16)\n",
            "(180000, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_signal(x, L=1024, S=512):\n",
        "    \"\"\"\n",
        "    x: (n_samples, n_channels)\n",
        "    returns: np.ndarray of shape (n_windows, L, n_channels)\n",
        "    \"\"\"\n",
        "\n",
        "    n_samples, n_channels = x.shape\n",
        "\n",
        "    n_windows = int(np.floor((n_samples - L) / S) + 1)\n",
        "    windows = []\n",
        "    for start in range(0, n_samples - L + 1, S):\n",
        "        windows.append(x[start:start+L, 1])\n",
        "    return np.stack(windows, axis=0)\n",
        "\n",
        "# apply to each state\n",
        "seg1 = segment_signal(data_state1, L=1024, S=512)\n",
        "seg3 = segment_signal(data_state3, L=1024, S=512)\n",
        "\n",
        "print(\"State1 windows:\", seg1.shape)  # e.g. (≈117, 1024, 15)\n",
        "print(\"State3 windows:\", seg3.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFiGU3vVyI0M",
        "outputId": "b2a43f5e-89fc-49a6-af9d-ed030494cce9"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State1 windows: (116, 1024)\n",
            "State3 windows: (116, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.vstack([seg1, seg3])\n",
        "y = np.concatenate([\n",
        "    np.zeros(len(seg1), dtype=np.int64),   # label 0 for state1\n",
        "    np.ones(len(seg3),  dtype=np.int64),   # label 1 for state3\n",
        "])\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape, \"unique labels:\", np.unique(y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2C4LSPh4exE",
        "outputId": "95830adb-c8da-461d-fb90-7671ef9ac418"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (232, 1024)\n",
            "y shape: (232,) unique labels: [0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not isinstance(X, torch.Tensor):\n",
        "    X = torch.from_numpy(X).float()\n",
        "if not isinstance(y, torch.Tensor):\n",
        "    y = torch.from_numpy(y)\n",
        "\n",
        "# instantiate and wrap in loader\n",
        "dataset = (X, y)\n",
        "loader  = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# xb, yb = next(iter(loader))\n",
        "print(\"Batch X:\", xb.shape)  # (32, 1024, 15)\n",
        "print(\"Batch y:\", yb.shape)  # (32,)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_yd-QYm4zuv",
        "outputId": "1c613919-6fb8-46c3-dfcd-f1f3871eb3ca"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch X: torch.Size([32, 1024])\n",
            "Batch y: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class TimeSeriesTransformer(nn.Module):\n",
        "    def __init__(self, n_channels=1, d_model=64, n_heads=4, num_layers=3, num_classes=2):\n",
        "        super().__init__()\n",
        "        # 1) per-step embedding\n",
        "        self.input_proj = nn.Linear(n_channels, d_model)\n",
        "        # 2) positional encoding\n",
        "        self.pos_enc = nn.Parameter(torch.randn(1, 1024, d_model))\n",
        "        # 3) transformer encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model, nhead=n_heads, dim_feedforward=4*d_model, dropout=0.1\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        # 4) classification head\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model//2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(d_model//2, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, L, C)\n",
        "        x = self.input_proj(x)                 # → (batch, L, d_model)\n",
        "        x = x + self.pos_enc[:, :x.size(1)]    # add positional embedding\n",
        "        x = x.permute(1, 0, 2)                 # → (L, batch, d_model) for Transformer\n",
        "        x = self.transformer(x)                # → (L, batch, d_model)\n",
        "        x = x.mean(dim=0)                      # global-average over time → (batch, d_model)\n",
        "        return self.classifier(x)              # → (batch, num_classes)\n"
      ],
      "metadata": {
        "id": "xEX-7Vip7fbD"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TimeSeriesTransformer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2HgwGA489xl",
        "outputId": "8d5d6223-bbc8-402d-f75b-2b2dafad807c"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)\n"
      ],
      "metadata": {
        "id": "u4iNpdLf35Er"
      },
      "execution_count": 56,
      "outputs": []
    }
  ]
}